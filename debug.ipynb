{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\CMIT\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "from torch import optim\n",
    "from torch.cuda import amp\n",
    "from torch.nn.modules import activation\n",
    "from torch.nn.modules.activation import Threshold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from eval import eval_net\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import utils\n",
    "import models\n",
    "from utils.dataset import BasicDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# dir_img = osp.join(\"..\", \"unet_dataset\", \"images\", \"trainval\")\n",
    "# dir_mask = osp.join(\"..\", \"unet_dataset\", \"labels\", \"trainval\")\n",
    "\n",
    "dir_img = osp.join(\".\", \"dataset0\", \"train\")\n",
    "dir_mask = osp.join(\".\", \"dataset0\", \"train_GT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_parallel(model):\n",
    "    return type(model) in (nn.parallel.DataParallel,\n",
    "                           nn.parallel.DistributedDataParallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Train the UNet on images and target masks',\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument('-e',\n",
    "                        '--epochs',\n",
    "                        metavar='E',\n",
    "                        type=int,\n",
    "                        default=5,\n",
    "                        help='Number of epochs',\n",
    "                        dest='epochs')\n",
    "    parser.add_argument('-b',\n",
    "                        '--batch_size',\n",
    "                        metavar='B',\n",
    "                        type=int,\n",
    "                        nargs='?',\n",
    "                        default=1,\n",
    "                        help='Batch size',\n",
    "                        dest='batchsize')\n",
    "    parser.add_argument('-l',\n",
    "                        '--learning_rate',\n",
    "                        metavar='LR',\n",
    "                        type=float,\n",
    "                        nargs='?',\n",
    "                        default=0.0001,\n",
    "                        help='Learning rate',\n",
    "                        dest='lr')\n",
    "    parser.add_argument('-f',\n",
    "                        '--load',\n",
    "                        dest='load',\n",
    "                        default=False,\n",
    "                        action='store_true',\n",
    "                        help='Load model from a .pth file')\n",
    "    parser.add_argument('-s',\n",
    "                        '--scale',\n",
    "                        dest='scale',\n",
    "                        type=float,\n",
    "                        default=0.5,\n",
    "                        help='Downscaling factor of the images')\n",
    "    parser.add_argument('-v',\n",
    "                        '--validation',\n",
    "                        dest='val',\n",
    "                        type=float,\n",
    "                        default=0.1,\n",
    "                        help='Percent of the data \\\n",
    "                              that is used as validation (0-100)')\n",
    "    parser.add_argument('-d',\n",
    "                        '--device',\n",
    "                        default='cpu',\n",
    "                        help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
    "    parser.add_argument('--local_rank',\n",
    "                        type=int,\n",
    "                        default=-1,\n",
    "                        help='DDP parameter, do not modify')\n",
    "    parser.add_argument('--model_type',\n",
    "                        type=str,\n",
    "                        default='utrans',\n",
    "                        help=\"Model which choosed.\")\n",
    "    parser.add_argument('--split_seed', type=int, default=None, help='')\n",
    "    return parser.parse_args(args=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def select_device(device='', batch_size=None):\n",
    "    # device = 'cpu' or '0' or '0,1,2,3'\n",
    "    s = f'UNetHX torch {torch.__version__} '\n",
    "    cpu = device.lower() == 'cpu'\n",
    "    if cpu:\n",
    "        os.environ[\n",
    "            'CUDA_VISIBLE_DEVICES'] = '-1'  # force torch.cuda.is_available() = False\n",
    "    elif device:  # non-cpu device requested\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = device  # set environment variable\n",
    "        assert torch.cuda.is_available(\n",
    "        ), f'CUDA unavailable, invalid device {device} requested'  # check availability\n",
    "\n",
    "    cuda = not cpu and torch.cuda.is_available()\n",
    "    if cuda:\n",
    "        n = torch.cuda.device_count()\n",
    "        if n > 1 and batch_size:  # check that batch_size is compatible with device_count\n",
    "            assert batch_size % n == 0, f'batch-size {batch_size} not multiple of GPU count {n}'\n",
    "        space = ' ' * len(s)\n",
    "        for i, d in enumerate(device.split(',') if device else range(n)):\n",
    "            p = torch.cuda.get_device_properties(i)\n",
    "            s += f\"{'' if i == 0 else space}CUDA:{d} ({p.name}, {p.total_memory / 1024 ** 2}MB)\\n\"  # bytes to MB\n",
    "    else:\n",
    "        s += 'CPU\\n'\n",
    "\n",
    "    logger.info(s)  # skip a line\n",
    "    return torch.device('cuda:0' if cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_net(model,\n",
    "              device,\n",
    "              epochs=5,\n",
    "              batch_size=1,\n",
    "              lr=0.001,\n",
    "              val_percent=0.1,\n",
    "              save_all_cp=True,\n",
    "              dir_checkpoint='runs',\n",
    "              split_seed=None):\n",
    "    transform_valid = tv.transforms.Compose([tv.transforms.ToTensor(),\n",
    "                                             tv.transforms.RandomCrop((400, 400))\n",
    "                                             ])\n",
    "    dataset = BasicDataset(dir_img, dir_mask, transform=transform_valid)\n",
    "    n_val = int(len(dataset) *\n",
    "                val_percent) if val_percent < 1 else int(val_percent)\n",
    "    n_train = len(dataset) - n_val\n",
    "    if split_seed:\n",
    "        train, val = random_split(\n",
    "            dataset, [n_train, n_val],\n",
    "            generator=torch.Generator().manual_seed(split_seed))\n",
    "    else:\n",
    "        train, val = random_split(dataset, [n_train, n_val])\n",
    "    if type(model) == nn.parallel.DistributedDataParallel:\n",
    "        train_loader = DataLoader(train,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=False,\n",
    "                                  num_workers=0,\n",
    "                                  pin_memory=True,\n",
    "                                  sampler=DistributedSampler(train))\n",
    "        val_loader = DataLoader(val,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                num_workers=0,\n",
    "                                pin_memory=True,\n",
    "                                drop_last=True,\n",
    "                                sampler=DistributedSampler(val))\n",
    "    else:\n",
    "        train_loader = DataLoader(train,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=0,\n",
    "                                  pin_memory=True)\n",
    "        val_loader = DataLoader(val,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                num_workers=0,\n",
    "                                pin_memory=True,\n",
    "                                drop_last=True)\n",
    "\n",
    "    logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Learning rate:   {lr}\n",
    "        Training size:   {n_train}\n",
    "        Validation size: {n_val}\n",
    "        Checkpoints:     {save_all_cp}\n",
    "        Device:          {device.type}\n",
    "    ''')\n",
    "\n",
    "    # loss = nn.BCEWithLogitsLoss()\n",
    "    # loss.__name__ = 'BCEWithLogitLoss'\n",
    "    # loss = nn.BCELoss()\n",
    "    # loss.__name__ = 'BCELoss'\n",
    "    loss = utils.losses.NoiseRobustDiceLoss(eps=1e-7, activation='sigmoid')\n",
    "    metrics = [\n",
    "        utils.metrics.Dice(threshold=0.5, activation='sigmoid'),\n",
    "        utils.metrics.Fscore(threshold=None, activation='sigmoid')\n",
    "    ]\n",
    "    optimizer = torch.optim.Adam([\n",
    "        dict(params=model.parameters(), lr=lr),\n",
    "    ])\n",
    "\n",
    "    train_epoch = utils.train.TrainEpoch(\n",
    "        model,\n",
    "        loss=loss,\n",
    "        metrics=metrics,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        verbose=True,\n",
    "    )\n",
    "    valid_epoch = utils.train.ValidEpoch(\n",
    "        model,\n",
    "        loss=loss,\n",
    "        metrics=metrics,\n",
    "        device=device,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    max_score = 0\n",
    "    os.makedirs(dir_checkpoint, exist_ok=True)\n",
    "    for i in range(0, epochs):\n",
    "        print('\\nEpoch: {}'.format(i + 1))\n",
    "        train_logs = train_epoch.run(train_loader)\n",
    "        valid_logs = valid_epoch.run(val_loader)\n",
    "\n",
    "        # do something (save model, change lr, etc.)\n",
    "        if max_score < valid_logs['dice_score']:\n",
    "            max_score = valid_logs['dice_score']\n",
    "            torch.save(model, osp.join(dir_checkpoint, 'best_model.pt'))\n",
    "            torch.save(model.state_dict(),\n",
    "                       osp.join(dir_checkpoint, 'best_model_dict.pth'))\n",
    "            print('Model saved!')\n",
    "\n",
    "        if save_all_cp:\n",
    "            torch.save(model.state_dict(),\n",
    "                       osp.join(dir_checkpoint, f'CP_epoch{i + 1}.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## if __name__ == '__main__':\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(levelname)s: %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batchsize=1, device='cpu', epochs=5, load=False, local_rank=-1, lr=0.0001, model_type='utrans', scale=0.5, split_seed=None, val=0.1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = get_args()\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: UNetHX torch 1.12.0 CPU\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = select_device(args.device, batch_size=args.batchsize)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using device cpu\n"
     ]
    }
   ],
   "source": [
    "logging.info(f'Using device {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import socket\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aug16_01-30-05'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_time = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MT_utrans_SS_None_LR_0.0001_BS_1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = f'MT_{args.model_type}_SS_{args.split_seed}_LR_{args.lr}_BS_{args.batchsize}'\n",
    "comment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\checkpoints\\\\Aug16_01-30-05_DESKTOP-V4LBDUN_MT_utrans_SS_None_LR_0.0001_BS_1'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_checkpoint = osp.join(\n",
    "    \".\", \"checkpoints\",\n",
    "    f\"{current_time}_{socket.gethostname()}_\" + comment)\n",
    "dir_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nets = {\n",
    "    # \"unet\": models.UNet,\n",
    "    # \"inunet\": InUNet,\n",
    "    # \"attunet\": AttU_Net,\n",
    "    # \"inattunet\": InAttU_Net,\n",
    "    # \"att2uneta\": Att2U_NetA,\n",
    "    # \"att2unetb\": Att2U_NetB,\n",
    "    # \"att2unetc\": Att2U_NetC,\n",
    "    # \"ecaunet\": ECAU_Net,\n",
    "    # \"gsaunet\": GsAUNet,\n",
    "    # \"utnet\": U_Transformer,\n",
    "    #\"ddrnet\": models.DualResNet,\n",
    "    \"utrans\": models.U_Transformer\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "models.utransformer.U_Transformer.U_Transformer"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_type = nets[args.model_type.lower()]\n",
    "net_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "net = net_type(in_channels=3, classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "U_Transformer(\n",
       "  (inc): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (MHSA): MultiHeadSelfAttention(\n",
       "    (query): MultiHeadDense()\n",
       "    (key): MultiHeadDense()\n",
       "    (value): MultiHeadDense()\n",
       "    (softmax): Softmax(dim=1)\n",
       "    (pe): PositionalEncodingPermute2D(\n",
       "      (penc): PositionalEncoding2D()\n",
       "    )\n",
       "  )\n",
       "  (up1): TransformerUp(\n",
       "    (MHCA): MultiHeadCrossAttention(\n",
       "      (Sconv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (Yconv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (query): MultiHeadDense()\n",
       "      (key): MultiHeadDense()\n",
       "      (value): MultiHeadDense()\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "      )\n",
       "      (Yconv2): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "      (softmax): Softmax(dim=1)\n",
       "      (Spe): PositionalEncodingPermute2D(\n",
       "        (penc): PositionalEncoding2D()\n",
       "      )\n",
       "      (Ype): PositionalEncodingPermute2D(\n",
       "        (penc): PositionalEncoding2D()\n",
       "      )\n",
       "    )\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up2): TransformerUp(\n",
       "    (MHCA): MultiHeadCrossAttention(\n",
       "      (Sconv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (Yconv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (query): MultiHeadDense()\n",
       "      (key): MultiHeadDense()\n",
       "      (value): MultiHeadDense()\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "      )\n",
       "      (Yconv2): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "      (softmax): Softmax(dim=1)\n",
       "      (Spe): PositionalEncodingPermute2D(\n",
       "        (penc): PositionalEncoding2D()\n",
       "      )\n",
       "      (Ype): PositionalEncodingPermute2D(\n",
       "        (penc): PositionalEncoding2D()\n",
       "      )\n",
       "    )\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up3): TransformerUp(\n",
       "    (MHCA): MultiHeadCrossAttention(\n",
       "      (Sconv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (Yconv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (query): MultiHeadDense()\n",
       "      (key): MultiHeadDense()\n",
       "      (value): MultiHeadDense()\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "      )\n",
       "      (Yconv2): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "      (softmax): Softmax(dim=1)\n",
       "      (Spe): PositionalEncodingPermute2D(\n",
       "        (penc): PositionalEncoding2D()\n",
       "      )\n",
       "      (Ype): PositionalEncodingPermute2D(\n",
       "        (penc): PositionalEncoding2D()\n",
       "      )\n",
       "    )\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = device.type != 'cpu'\n",
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "net = net.to(device=device)\n",
    "net = net.module if is_parallel(net) else net\n",
    "net = net.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if args.load:\n",
    "    net.load_state_dict(torch.load(args.load, map_location=device))\n",
    "    logging.info(f'Model loaded from {args.load}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Creating dataset with 2074 examples\n",
      "INFO: Starting training:\n",
      "        Epochs:          5\n",
      "        Batch size:      1\n",
      "        Learning rate:   0.0001\n",
      "        Training size:   1867\n",
      "        Validation size: 207\n",
      "        Checkpoints:     True\n",
      "        Device:          cpu\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "train:   0%|          | 2/1867 [25:25<394:49:37, 762.13s/it, noise_robust_dice_loss - 0.75, dice_score - 0.4646, f_score - 0.3646]  "
     ]
    }
   ],
   "source": [
    "train_net(model=net,\n",
    "          epochs=args.epochs,\n",
    "          batch_size=args.batchsize,\n",
    "          lr=args.lr,\n",
    "          device=device,\n",
    "          val_percent=args.val,\n",
    "          dir_checkpoint=dir_checkpoint,\n",
    "          split_seed=args.split_seed,\n",
    "          save_all_cp=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## train_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model=net\n",
    "epochs=args.epochs\n",
    "batch_size=args.batchsize\n",
    "lr=args.lr\n",
    "device=device\n",
    "val_percent=args.val\n",
    "dir_checkpoint=dir_checkpoint\n",
    "split_seed=args.split_seed\n",
    "save_all_cp=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transform_valid = tv.transforms.Compose([tv.transforms.ToTensor(),\n",
    "                                         tv.transforms.RandomCrop((400, 400))\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Creating dataset with 2074 examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.dataset.BasicDataset at 0x2223bc43f48>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = BasicDataset(dir_img, dir_mask, transform=transform_valid)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_val = int(len(dataset) *\n",
    "            val_percent) if val_percent < 1 else int(val_percent)\n",
    "n_train = len(dataset) - n_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataset.Subset'>\n"
     ]
    }
   ],
   "source": [
    "if split_seed:\n",
    "    train, val = random_split(\n",
    "        dataset, [n_train, n_val],\n",
    "        generator=torch.Generator().manual_seed(split_seed))\n",
    "else:\n",
    "    train, val = random_split(dataset, [n_train, n_val])\n",
    "print(type(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if type(model) == nn.parallel.DistributedDataParallel:\n",
    "    train_loader = DataLoader(train,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=0,\n",
    "                              pin_memory=True,\n",
    "                              sampler=DistributedSampler(train))\n",
    "    val_loader = DataLoader(val,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=0,\n",
    "                            pin_memory=True,\n",
    "                            drop_last=True,\n",
    "                            sampler=DistributedSampler(val))\n",
    "else:\n",
    "    train_loader = DataLoader(train,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=1,\n",
    "                              pin_memory=True)\n",
    "    val_loader = DataLoader(val,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=1,\n",
    "                            pin_memory=True,\n",
    "                            drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method size of Tensor object at 0x000002223BC3FE08>\n"
     ]
    }
   ],
   "source": [
    "for i, (train, GT) in enumerate(train_loader):\n",
    "    print(train.size)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## DataSet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import logging\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Creating dataset with 2074 examples\n"
     ]
    }
   ],
   "source": [
    "imgs_dir = dir_img\n",
    "masks_dir = dir_mask\n",
    "mask_suffix = '_segmentation'\n",
    "transform = transform_valid\n",
    "ids = [\n",
    "            osp.splitext(file)[0] for file in os.listdir(imgs_dir)\n",
    "            if not file.startswith('.')\n",
    "        ]\n",
    "logging.info(f'Creating dataset with {len(ids)} examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(img_nd):\n",
    "    if len(img_nd.shape) == 2:\n",
    "        img_nd = np.expand_dims(img_nd, axis=2)\n",
    "        # img_nd = np.repeat(img_nd, 3, 2) # make 1 channel pic to 3 channels pic\n",
    "\n",
    "    # HWC to CHW\n",
    "    # img_trans = img_nd.transpose((2, 0, 1))\n",
    "    img_trans = img_nd\n",
    "\n",
    "    if 255 >= img_trans.max() > 1 and img_trans.min() > 0:\n",
    "        # Normally UINT8 pic\n",
    "        img_trans = img_trans / 255.0\n",
    "    elif 0 < img_trans.all() <= 1:\n",
    "        # Normally FLOAT pic\n",
    "        pass\n",
    "    else:\n",
    "        # DICOM pic\n",
    "        pass\n",
    "\n",
    "    return img_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "idx = ids[0]\n",
    "mask_file = glob(\n",
    "    osp.join(masks_dir, idx + mask_suffix + '.*'))\n",
    "img_file = glob(osp.join(imgs_dir, idx + '.*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mask = np.array(Image.open(mask_file[0]))\n",
    "img = np.array(Image.open(img_file[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(767, 1022, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "seed = torch.random.seed()\n",
    "\n",
    "if transform:\n",
    "    torch.random.manual_seed(seed)\n",
    "    img = transform(img)\n",
    "    torch.random.manual_seed(seed)\n",
    "    mask = transform(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 400, 400])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trans = tv.transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image = trans(img)\n",
    "label = trans(mask)\n",
    "image.show()\n",
    "label.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = preprocess(img)\n",
    "mask = preprocess(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('CMIT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9eae43bdedb44189c647f748676127cf9856ac2c81e65d1a765d4b39a8db98c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
